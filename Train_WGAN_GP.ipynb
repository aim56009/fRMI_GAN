{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wgan-gp_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvschw/fmriGAN/blob/main/Masterarbeit_WGAN_GP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8k9AL_3HW8I"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXZBmpZ3DhvB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install nilearn\n",
        "!pip install wandb -q\n",
        "!pip install nltools\n",
        "\n",
        "%cd \"/content/gdrive/MyDrive/Masterarbeit\"\n",
        "%pylab inline\n",
        "\n",
        "import scipy\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import datetime\n",
        "import glob\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from scipy.ndimage import zoom\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.autograd import Variable\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from model_wgan_gp_tanh import Discriminator, Generator, initialize_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyWRZFF2Dbb"
      },
      "source": [
        "## Choose Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiED3ecy2GIm"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 4\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS_IMG = 1\n",
        "Z_DIM = 1000\n",
        "NUM_EPOCHS = 101\n",
        "FEATURES_CRITIC = 32\n",
        "FEATURES_GEN = 32\n",
        "CRITIC_ITERATIONS = 5\n",
        "LAMBDA_GP = 10\n",
        "load_pretrained = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZdGmBkSIZod"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC730WgwIZoe"
      },
      "source": [
        "cfg = {\n",
        "    'env': 'COLAB',\n",
        "    'usr': \"MICHAEL\",\n",
        "    'version_name': 'v3.1',\n",
        "    'epochs': NUM_EPOCHS,                 #  epoch = (Number of iterations * batch size) / total number of images in training\n",
        "    'batch_size': BATCH_SIZE, \n",
        "    'learning_rate':  LEARNING_RATE,\n",
        "    'dbg_rescaled': 0,\n",
        "    'labels': ['footright'],\n",
        "    'smoothing': '0mm', \n",
        "    'latent_dim': Z_DIM,}\n",
        "    \n",
        "#DO NOT EDIT\n",
        "cfg['expid'] = cfg['usr'] + '_' + cfg['version_name'] + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_' + '_'.join(cfg['labels'])  + '_SS' + cfg['smoothing']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9CYFgKOIZof",
        "outputId": "1a99f7f6-b3a5-4dd7-ecb0-0a2982c734a6"
      },
      "source": [
        "tags=['Brain_GAN', 'Initial Run', '_'.join(cfg['labels']), 'SS'+cfg['smoothing'],\n",
        "      'latentdim'+str(cfg['latent_dim']), 'batch_size'+str(cfg['batch_size'])]\n",
        "print(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brain_GAN', 'Initial Run', 'footright', 'SS0mm', 'latentdim1000', 'batch_size4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRbX9EZOIZoh"
      },
      "source": [
        "gpu = True\n",
        "workers = 0\n",
        "LAMBDA= LAMBDA_GP\n",
        "_eps = 1e-15\n",
        "\n",
        "PROJECT_DIR=\"/content/gdrive/MyDrive/Masterarbeit\"\n",
        "PATH_TO_DATA=\"/content/gdrive/MyDrive/Masterarbeit/tstat_\"+ cfg['smoothing']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls3-Wv39IZoi"
      },
      "source": [
        "Create directory for saving models when training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqrppWY53YEY",
        "outputId": "e3816964-8a4f-4ce3-9702-fb37aec1a6a7"
      },
      "source": [
        "imgREF = nib.load(os.path.join(PROJECT_DIR, 'tstat_' + cfg['smoothing'], cfg['labels'][0], 'sub100307.nii.gz'))\n",
        "\n",
        "PATH_CHECKPOINT_MOD = os.path.join(PROJECT_DIR, 'checkpoint_models', cfg['expid'])\n",
        "\n",
        "if not os.path.isdir(PATH_CHECKPOINT_MOD):\n",
        "    print('Creating directory: ', PATH_CHECKPOINT_MOD)\n",
        "    os.makedirs(PATH_CHECKPOINT_MOD)\n",
        "\n",
        "\n",
        "#PATH_CHECKPOINT_IMG = os.path.join(PROJECT_DIR, 'checkpoint_images', cfg['expid'])\n",
        "#if not os.path.isdir(PATH_CHECKPOINT_IMG):\n",
        "#    print('Creating directory: ', PATH_CHECKPOINT_IMG)\n",
        "#    os.makedirs(PATH_CHECKPOINT_IMG)\n",
        "\n",
        "#for fl in glob.glob(os.path.join(PATH_CHECKPOINT_IMG, '*.nii.gz')):\n",
        "#    print('removing ', fl)\n",
        "#    os.remove(fl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory:  /content/gdrive/MyDrive/Masterarbeit/checkpoint_models/MICHAEL_v3.1_20211130-132728_footright_SS0mm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaAHECl9UjHc"
      },
      "source": [
        "def do_log(i, some_dict):\n",
        "    wandb.log(some_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uLgi-h8CUM"
      },
      "source": [
        "# **Dataloader** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaP4oetE8Mpv"
      },
      "source": [
        "class NiftiDataset_(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, labels, n, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.mask = np.load(\"mask_dil64.npy\")\n",
        "\n",
        "        # get the files\n",
        "        for iLabel in range(len(labels)):\n",
        "            file_names = sorted(glob.glob(os.path.join(data_dir, labels[iLabel], \"*.nii.gz\")))\n",
        "\n",
        "            if iLabel == 0:\n",
        "                self.data = np.array(file_names[:n])\n",
        "                self.labels = np.array(np.repeat(labels[iLabel], len(self.data)))\n",
        "            else:\n",
        "                self.data = np.append(self.data, file_names[:n])\n",
        "                self.labels = np.append(self.labels, np.repeat(labels[iLabel], len(self.data)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = np.nan_to_num(nib.load(self.data[idx]).get_fdata())  \n",
        "        img[np.isnan(img)] = 0\n",
        "\n",
        "        dims = img.shape\n",
        "        img_ = zoom(img, (64/dims[0], 64/dims[1], 64/dims[2]))\n",
        "\n",
        "        img_ = (img_-np.min(img_))/(np.max(img_)-np.min(img_))\n",
        "        img_ = 2*img_-1\n",
        "\n",
        "        mask_img = img_ * self.mask\n",
        "\n",
        "        mask_img = torch.tensor(mask_img)\n",
        "        mask_img = mask_img.unsqueeze(0)\n",
        "        \n",
        "\n",
        "\n",
        "        sample = {'img': mask_img.float(), 'label': self.labels[idx]}\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdoVqfRTXz73"
      },
      "source": [
        "dataset = NiftiDataset_(PATH_TO_DATA, cfg['labels'], 802) # was 709 for handleft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMjMxHq4yvN"
      },
      "source": [
        "loader = torch.utils.data.DataLoader(dataset,batch_size=cfg['batch_size'], shuffle=True, num_workers=workers, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqhZaJDszSQ"
      },
      "source": [
        "# **Training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCs3094HLTu"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsFlFbH0WA4I"
      },
      "source": [
        "def calc_gradient_penalty(model, x, x_gen, w=10):\n",
        "    assert x.size()==x_gen.size()                                               # check if real and sample size match\n",
        "    alpha_size = tuple((len(x), *(1,)*(x.dim()-1)))\n",
        "    alpha_t = torch.cuda.FloatTensor if x.is_cuda else torch.Tensor\n",
        "    alpha = alpha_t(*alpha_size).uniform_()\n",
        "    x_hat = x.data*alpha + x_gen.data*(1-alpha)\n",
        "    x_hat = Variable(x_hat, requires_grad=True)\n",
        "\n",
        "    def eps_norm(x):\n",
        "        x = x.view(len(x), -1)\n",
        "        return (x*x+_eps).sum(-1).sqrt()\n",
        "    def bi_penalty(x):\n",
        "        return (x-1)**2\n",
        "\n",
        "    grad_xhat = torch.autograd.grad(model(x_hat).sum(), x_hat, create_graph=True, only_inputs=True)[0]\n",
        "    penalty = w*bi_penalty(eps_norm(grad_xhat)).mean()\n",
        "    return penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZlfcFApbTf"
      },
      "source": [
        "def saveResampledNifti(generatedData64, imgREF, fNameOut):\n",
        "    dims = imgREF.shape\n",
        "    generatedDataOrgRes = zoom(generatedData64, (dims[0]/64, dims[1]/64, dims[2]/64))\n",
        "    imgRes = nib.Nifti1Image(generatedDataOrgRes, affine = imgREF.affine)\n",
        "    nib.save(imgRes, fNameOut)\n",
        "\n",
        "def generate_fake(generator, z_dim, output_dir, n_fakes=100, batch_size=1):\n",
        "                print('saving into %s' % output_dir)\n",
        "                for k in tqdm(range(n_fakes)):\n",
        "\n",
        "                    noise = torch.randn(batch_size, z_dim, 1, 1, 1).to(device)\n",
        "                    dat = generator(noise)\n",
        "\n",
        "                    fNameOut = os.path.join(output_dir,'fake'+'{:03}'.format(k+1) + '.nii.gz')\n",
        "                    generatedData64 = np.squeeze(dat.data.cpu().numpy())\n",
        "                    saveResampledNifti(generatedData64, imgREF, fNameOut)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDdaqg75ZBy"
      },
      "source": [
        "Initialize the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEUwj3m_soRW"
      },
      "source": [
        "gen = Generator(cfg['latent_dim'], CHANNELS_IMG, FEATURES_GEN).to(device)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
        "\n",
        "if load_pretrained:\n",
        "    gen.load_state_dict(torch.load(\"checkpoint_models/tanh/ckpt_gen_iter000100.pth\"))\n",
        "    critic.load_state_dict(torch.load(\"checkpoint_models/tanh/ckpt_critic_iter000100.pth\"))\n",
        "\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=cfg['learning_rate'], betas=(0.0, 0.9))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=cfg['learning_rate'], betas=(0.0, 0.9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rLQ-Kg96J1S"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1svzDGt-CFa"
      },
      "source": [
        "def train(nbr_models_saved=10):\n",
        "    \n",
        "    gen.train()\n",
        "    critic.train()\n",
        "\n",
        "    \n",
        "    wandb.init(\n",
        "    entity=\"ml4ni\",\n",
        "    project='alpha-wgan',\n",
        "    name=cfg['expid'], \n",
        "    notes='https://colab.research.google.com/drive/10hVK7wxbZRzynuxahMx5L2ziLwjdQx89#scrollTo=zIt_iSG52ug4', \n",
        "    tags=tags,\n",
        "    config=cfg)\n",
        "\n",
        "    config = wandb.config\n",
        "    \n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        for batch_idx, real in enumerate(loader):\n",
        "\n",
        "            real = real[\"img\"].to(device)\n",
        "            cur_batch_size = real.shape[0]\n",
        "\n",
        "            # Train Critic: max E[critic(real)] - E[critic(fake)] equivalent to minimizing the negative of that\n",
        "            for _ in range(CRITIC_ITERATIONS):\n",
        "                noise = torch.randn(cur_batch_size, Z_DIM, 1, 1,1).to(device)\n",
        "                fake = gen(noise)\n",
        "                critic_real = critic(real).reshape(-1)\n",
        "                critic_fake = critic(fake).reshape(-1)\n",
        "                gp = calc_gradient_penalty(critic, real, fake)\n",
        "                loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp  \n",
        "                               \n",
        "                \n",
        "                critic.zero_grad()\n",
        "                loss_critic.backward(retain_graph=True)\n",
        "                opt_critic.step()\n",
        "\n",
        "\n",
        "            # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "            \n",
        "            gen_fake = critic(fake).reshape(-1)\n",
        "            loss_gen = -torch.mean(gen_fake) \n",
        "            gen.zero_grad()\n",
        "            loss_gen.backward()\n",
        "            opt_gen.step()\n",
        "            \n",
        "            if batch_idx % cur_batch_size == 0 and batch_idx > 0:\n",
        "                print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
        "                      Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\")\n",
        "\n",
        "            do_log(epoch, { \"D:\":loss_critic, \"G:\":loss_gen})\n",
        "\n",
        "        if epoch%nbr_models_saved ==0:\n",
        "            fNameOut = os.path.join(PATH_CHECKPOINT_MOD, 'ckpt_gen_iter' + '{:06}'.format(epoch+1) + '.pth')\n",
        "            print('Saving ', fNameOut)\n",
        "            torch.save(gen.state_dict(), fNameOut)\n",
        "              \n",
        "            fNameOut = os.path.join(PATH_CHECKPOINT_MOD, 'ckpt_critic_iter' + '{:06}'.format(epoch+1) + '.pth')\n",
        "            print('Saving ', fNameOut)\n",
        "            torch.save(critic.state_dict(), fNameOut)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX4IczIXjgSl"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kSJB7T2_PM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}